fastapi==0.105.0
uvicorn==0.24.0
llama-cpp-python